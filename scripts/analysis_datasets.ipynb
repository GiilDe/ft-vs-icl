{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-12 23:58:15 | WARNING | datasets.builder | Using custom data configuration default\n",
      "2023-12-12 23:58:15 | WARNING | datasets.builder | Reusing dataset sst2 (/home/joberant/NLP_2223/nadavmagar/.cache/sst2/default/2.0.0/9896208a8d85db057ac50c72282bcb8fe755accc671a57dd8059d4e130961ed5)\n",
      "100%|██████████| 3/3 [00:00<00:00, 486.48it/s]\n",
      "2023-12-12 23:58:16 | WARNING | datasets.arrow_dataset | Loading cached processed dataset at /home/joberant/NLP_2223/nadavmagar/.cache/sst2/default/2.0.0/9896208a8d85db057ac50c72282bcb8fe755accc671a57dd8059d4e130961ed5/cache-e02e028727bd4063.arrow\n",
      "2023-12-12 23:58:18 | WARNING | datasets.builder | Reusing dataset super_glue (/home/joberant/NLP_2223/nadavmagar/.cache/super_glue/cb/1.0.2/d040c658e2ddef6934fdd97deb45c777b6ff50c524781ea434e7219b56a428a7)\n",
      "100%|██████████| 3/3 [00:00<00:00, 550.58it/s]\n",
      "2023-12-12 23:58:19 | WARNING | datasets.arrow_dataset | Loading cached processed dataset at /home/joberant/NLP_2223/nadavmagar/.cache/super_glue/cb/1.0.2/d040c658e2ddef6934fdd97deb45c777b6ff50c524781ea434e7219b56a428a7/cache-d0048607b6e2a287.arrow\n",
      "2023-12-12 23:58:23 | WARNING | datasets.builder | Using custom data configuration SetFit--sst5-0c891184cb873f87\n",
      "2023-12-12 23:58:23 | WARNING | datasets.builder | Reusing dataset json (/home/joberant/NLP_2223/nadavmagar/.cache/SetFit___json/SetFit--sst5-0c891184cb873f87/0.0.0/a3e658c4731e59120d44081ac10bf85dc7e1388126b92338344ce9661907f253)\n",
      "100%|██████████| 3/3 [00:00<00:00, 585.28it/s]\n",
      "2023-12-12 23:58:24 | WARNING | datasets.arrow_dataset | Loading cached processed dataset at /home/joberant/NLP_2223/nadavmagar/.cache/SetFit___json/SetFit--sst5-0c891184cb873f87/0.0.0/a3e658c4731e59120d44081ac10bf85dc7e1388126b92338344ce9661907f253/cache-a3d61ec9a4a4f362.arrow\n",
      "2023-12-12 23:58:25 | WARNING | datasets.builder | Using custom data configuration default\n",
      "2023-12-12 23:58:25 | WARNING | datasets.builder | Reusing dataset rotten_tomatoes (/home/joberant/NLP_2223/nadavmagar/.cache/rotten_tomatoes/default/1.0.0/40d411e45a6ce3484deed7cc15b82a53dad9a72aafd9f86f8f227134bec5ca46)\n",
      "100%|██████████| 3/3 [00:00<00:00, 289.89it/s]\n",
      "100%|██████████| 8530/8530 [00:02<00:00, 3587.03ex/s]\n",
      "2023-12-12 23:58:31 | WARNING | datasets.builder | Using custom data configuration SetFit--subj-693a635c625bebac\n",
      "2023-12-12 23:58:31 | WARNING | datasets.builder | Reusing dataset json (/home/joberant/NLP_2223/nadavmagar/.cache/SetFit___json/SetFit--subj-693a635c625bebac/0.0.0/a3e658c4731e59120d44081ac10bf85dc7e1388126b92338344ce9661907f253)\n",
      "100%|██████████| 2/2 [00:00<00:00, 728.49it/s]\n",
      "100%|██████████| 8000/8000 [00:02<00:00, 3862.90ex/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------ sst2 ------------------\n",
      "sst2 length 67349\n",
      "sst2 avg_toks per sample 55.42990987245542\n",
      "------------------ ('super_glue', 'cb') ------------------\n",
      "('super_glue', 'cb') length 250\n",
      "('super_glue', 'cb') avg_toks per sample 295.804\n",
      "------------------ SetFit/sst5 ------------------\n",
      "SetFit/sst5 length 8544\n",
      "SetFit/sst5 avg_toks per sample 102.9492041198502\n",
      "------------------ rotten_tomatoes ------------------\n",
      "rotten_tomatoes length 8530\n",
      "rotten_tomatoes avg_toks per sample 113.3852286049238\n",
      "------------------ SetFit/subj ------------------\n",
      "SetFit/subj length 8000\n",
      "SetFit/subj avg_toks per sample 129.23025\n"
     ]
    }
   ],
   "source": [
    "import datasets\n",
    "\n",
    "from argparse import Namespace\n",
    "from collections import namedtuple\n",
    "from fairseq.data.dictionary import Dictionary\n",
    "from fairseq.data.encoders.gpt2_bpe import GPT2BPE\n",
    "\n",
    "Cfg = namedtuple(\"Cfg\", [\"gpt2_encoder_json\", \"gpt2_vocab_bpe\"])\n",
    "cfg = Cfg(\"../artifacts/gpt_icl/encoder.json\", \"../artifacts/gpt_icl/vocab.bpe\")\n",
    "tokenizer =  GPT2BPE(\n",
    "    cfg=cfg,\n",
    ")\n",
    "dictionary = Dictionary.load(\"../artifacts/gpt_icl/en_dense_lm_1_3b/dict.txt\")\n",
    "text_cols = {'premise', 'hypothesis', 'text', 'sentence'}\n",
    "tasks = ['sst2', ('super_glue', 'cb'), 'SetFit/sst5', 'rotten_tomatoes', 'SetFit/subj']\n",
    "lengths = []\n",
    "sample_sizes = []\n",
    "for task in tasks:\n",
    "    dataset = datasets.load_dataset(task if isinstance(task, str) else task[0], task[1] if isinstance(task, tuple) else None)\n",
    "    text_col = list(text_cols.intersection(set(dataset['train'].column_names)))[0]\n",
    "    dataset_l = dataset['train'].map(lambda d: {'l': len(tokenizer.encode(d[text_col]))})\n",
    "    avg_toks = sum(list(dataset_l['l'])) / len(dataset['train'])\n",
    "    lengths.append(len(dataset['train'])) # print(task, \"length\", len(dataset['train']))\n",
    "    sample_sizes.append(avg_toks) # print(task, \"avg_toks per sample\", avg_toks)\n",
    "\n",
    "for task in tasks:\n",
    "    print(\"------------------\", task, \"------------------\")\n",
    "    print(task, \"length\", lengths[tasks.index(task)])\n",
    "    print(task, \"avg_toks per sample\", sample_sizes[tasks.index(task)])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ft-vs-icl-clean",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
